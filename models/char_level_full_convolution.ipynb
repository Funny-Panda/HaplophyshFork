{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: No GPU, all there is is:\n",
      "- PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as k\n",
    "import numpy as np\n",
    "from models import dataset_ops\n",
    "from models import vectorization_ops\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_fscore_support, accuracy_score\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', None)  # show all columns\n",
    "GPUs = tf.config.list_physical_devices('GPU')\n",
    "if GPUs is None or len(GPUs) == 0:\n",
    "    print(\"WARNING: No GPU, all there is is:\")\n",
    "    for device in tf.config.list_physical_devices():\n",
    "        print(f'- {device}')\n",
    "else:\n",
    "    for gpu in GPUs:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"Initialized\", gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(         url\n type        \n 0     344821\n 1      75643,\n          url\n type        \n 0     241374\n 1      52950,\n          url\n type        \n 0     103447\n 1      22693)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train, data_validation, data = dataset_ops.load_data(split_ratio=0.3, random_state=42)\n",
    "data.groupby('type').aggregate('count'), data_train.groupby('type').aggregate('count'), data_validation.groupby('type').aggregate('count'),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Char vocab size: 150\n"
     ]
    }
   ],
   "source": [
    "char_vectorizer = vectorization_ops.create_char_vectorizer(data_train['url'])\n",
    "LC = len(char_vectorizer.word_counts)\n",
    "print('Char vocab size:', LC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: ({'char': TensorSpec(shape=(200,), dtype=tf.float64, name=None)}, TensorSpec(shape=(), dtype=tf.int32, name=None)) \n",
      "Valid: ({'char': TensorSpec(shape=(200,), dtype=tf.float64, name=None)}, TensorSpec(shape=(), dtype=tf.int32, name=None))\n"
     ]
    }
   ],
   "source": [
    "dataset_train = dataset_ops.create_dataset_generator(None, char_vectorizer, data_train)\\\n",
    "    .shuffle(10000)\\\n",
    "    .prefetch(10000) #.batch(15*1024)\n",
    "dataset_validation = dataset_ops.create_dataset_generator(None, char_vectorizer, data_validation)\\\n",
    "    .shuffle(10000)\\\n",
    "    .prefetch(10000) #.batch(15*1024)\n",
    "\n",
    "print('Train:', dataset_train.element_spec, '\\nValid:', dataset_validation.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char (InputLayer)               [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 200, 16)      2432        char[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "char_conv_3 (Conv1D)            (None, 200, 32)      1568        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "char_conv_5 (Conv1D)            (None, 200, 32)      2592        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 100, 32)      0           char_conv_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 100, 32)      0           char_conv_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 100, 64)      0           max_pooling1d_2[0][0]            \n",
      "                                                                 max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 6400)         0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "char_dropout (Dropout)          (None, 6400)         0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "char_dense (Dense)              (None, 512)          3277312     char_dropout[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          65664       char_dense[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_comb_out (Dense)          (None, 1)            129         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,349,697\n",
      "Trainable params: 3,349,697\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "def create_conv_subnet(input_layer, conv_kernel_sizes, prefix=''):\n",
    "    convolutions = list()\n",
    "    for kernel_size in conv_kernel_sizes:\n",
    "        x = k.layers.Conv1D(\n",
    "            filters=32,\n",
    "            kernel_size=kernel_size,\n",
    "            padding='same',\n",
    "            activation='relu',\n",
    "            name=f'{prefix}_conv_{kernel_size}'\n",
    "        )(input_layer)\n",
    "        x = k.layers.MaxPool1D()(x)\n",
    "        convolutions.append(x)\n",
    "\n",
    "    x = k.layers.concatenate(convolutions, axis=2)\n",
    "    x = k.layers.Flatten()(x)\n",
    "    x = k.layers.Dropout(0.5, name=f'{prefix}_dropout')(x)\n",
    "    x = k.layers.Dense(512, name=f'{prefix}_dense', activation='relu')(x)\n",
    "    return x\n",
    "\n",
    "def create_url_net(input_length, emb_dim, conv_kernel_sizes):\n",
    "    char_input = k.layers.Input(shape=[input_length], name='char')\n",
    "\n",
    "    x = create_conv_subnet(\n",
    "        k.layers.Embedding(2+LC, emb_dim, mask_zero=True)(char_input),\n",
    "        conv_kernel_sizes,\n",
    "        'char'\n",
    "    )\n",
    "\n",
    "    x = k.layers.Dense(128, activation='relu', name='dense_1')(x)\n",
    "    x = k.layers.Dense(1, activation='sigmoid', name='dense_comb_out')(x)\n",
    "\n",
    "    model = k.models.Model(inputs=[char_input], outputs=[x])\n",
    "    return model\n",
    "\n",
    "model = create_url_net(\n",
    "    input_length=200,\n",
    "    emb_dim=16,\n",
    "    conv_kernel_sizes=[3,5]\n",
    ")\n",
    "model.compile(\n",
    "    optimizer=k.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['binary_accuracy']#, k.metrics.Precision(), k.metrics.Recall()]\n",
    ")\n",
    "#     loss='binary_crossentropy',\n",
    "model.summary()\n",
    "k.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " TypeError: `generator` yielded an element that could not be converted to the expected type. The expected type was int32, but the yielded element was tf.Tensor(b'bad', shape=(), dtype=string).\nTraceback (most recent call last):\n\n  File \"C:\\Users\\13215\\.conda\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 982, in generator_py_func\n    dtype=dtype.as_numpy_dtype))\n\n  File \"C:\\Users\\13215\\.conda\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 209, in _convert\n    result = np.asarray(value, dtype=dtype, order=\"C\")\n\n  File \"C:\\Users\\13215\\.conda\\envs\\tens\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 83, in asarray\n    return array(a, dtype, copy=False, order=order)\n\nValueError: invalid literal for int() with base 10: b'bad'\n\n\nDuring handling of the above exception, another exception occurred:\n\n\nTraceback (most recent call last):\n\n  File \"C:\\Users\\13215\\.conda\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\13215\\.conda\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 645, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\13215\\.conda\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 991, in generator_py_func\n    sys.exc_info()[2])\n\n  File \"C:\\Users\\13215\\.conda\\envs\\tens\\lib\\site-packages\\six.py\", line 702, in reraise\n    raise value.with_traceback(tb)\n\n  File \"C:\\Users\\13215\\.conda\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 982, in generator_py_func\n    dtype=dtype.as_numpy_dtype))\n\n  File \"C:\\Users\\13215\\.conda\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 209, in _convert\n    result = np.asarray(value, dtype=dtype, order=\"C\")\n\n  File \"C:\\Users\\13215\\.conda\\envs\\tens\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 83, in asarray\n    return array(a, dtype, copy=False, order=order)\n\nTypeError: `generator` yielded an element that could not be converted to the expected type. The expected type was int32, but the yielded element was tf.Tensor(b'bad', shape=(), dtype=string).\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_1220]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_4740\\1583441956.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      7\u001B[0m     callbacks=[\n\u001B[0;32m      8\u001B[0m         \u001B[0mk\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mEarlyStopping\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmonitor\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'val_loss'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpatience\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m         \u001B[0mk\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mModelCheckpoint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'./checkpoints'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     10\u001B[0m     ],\n\u001B[0;32m     11\u001B[0m )\n",
      "\u001B[1;32m~\\.conda\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1181\u001B[0m                 _r=1):\n\u001B[0;32m   1182\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1183\u001B[1;33m               \u001B[0mtmp_logs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1184\u001B[0m               \u001B[1;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1185\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    887\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    888\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 889\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    890\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    891\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m_call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    948\u001B[0m         \u001B[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    949\u001B[0m         \u001B[1;31m# stateless function.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 950\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    951\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    952\u001B[0m       \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfiltered_flat_args\u001B[0m \u001B[1;33m=\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   3022\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[0;32m   3023\u001B[0m     return graph_function._call_flat(\n\u001B[1;32m-> 3024\u001B[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[0m\u001B[0;32m   3025\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3026\u001B[0m   \u001B[1;33m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1959\u001B[0m       \u001B[1;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1960\u001B[0m       return self._build_call_outputs(self._inference_function.call(\n\u001B[1;32m-> 1961\u001B[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[0m\u001B[0;32m   1962\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001B[0;32m   1963\u001B[0m         \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    594\u001B[0m               \u001B[0minputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    595\u001B[0m               \u001B[0mattrs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mattrs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 596\u001B[1;33m               ctx=ctx)\n\u001B[0m\u001B[0;32m    597\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    598\u001B[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001B[1;32m~\\.conda\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     58\u001B[0m     \u001B[0mctx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     59\u001B[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[1;32m---> 60\u001B[1;33m                                         inputs, attrs, num_outputs)\n\u001B[0m\u001B[0;32m     61\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     62\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mInvalidArgumentError\u001B[0m:  TypeError: `generator` yielded an element that could not be converted to the expected type. The expected type was int32, but the yielded element was tf.Tensor(b'bad', shape=(), dtype=string).\nTraceback (most recent call last):\n\n  File \"C:\\Users\\13215\\.conda\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 982, in generator_py_func\n    dtype=dtype.as_numpy_dtype))\n\n  File \"C:\\Users\\13215\\.conda\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 209, in _convert\n    result = np.asarray(value, dtype=dtype, order=\"C\")\n\n  File \"C:\\Users\\13215\\.conda\\envs\\tens\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 83, in asarray\n    return array(a, dtype, copy=False, order=order)\n\nValueError: invalid literal for int() with base 10: b'bad'\n\n\nDuring handling of the above exception, another exception occurred:\n\n\nTraceback (most recent call last):\n\n  File \"C:\\Users\\13215\\.conda\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\13215\\.conda\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 645, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\13215\\.conda\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 991, in generator_py_func\n    sys.exc_info()[2])\n\n  File \"C:\\Users\\13215\\.conda\\envs\\tens\\lib\\site-packages\\six.py\", line 702, in reraise\n    raise value.with_traceback(tb)\n\n  File \"C:\\Users\\13215\\.conda\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 982, in generator_py_func\n    dtype=dtype.as_numpy_dtype))\n\n  File \"C:\\Users\\13215\\.conda\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 209, in _convert\n    result = np.asarray(value, dtype=dtype, order=\"C\")\n\n  File \"C:\\Users\\13215\\.conda\\envs\\tens\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 83, in asarray\n    return array(a, dtype, copy=False, order=order)\n\nTypeError: `generator` yielded an element that could not be converted to the expected type. The expected type was int32, but the yielded element was tf.Tensor(b'bad', shape=(), dtype=string).\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_1220]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "bs=256*8\n",
    "\n",
    "model.fit(\n",
    "    dataset_train.batch(bs),\n",
    "    epochs=100,\n",
    "    validation_data=dataset_validation.batch(bs),\n",
    "    callbacks=[\n",
    "        k.callbacks.EarlyStopping(monitor='val_loss', patience=3),\n",
    "        k.callbacks.ModelCheckpoint('./checkpoints', verbose=0)\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save('full_convolution')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bs=256*8\n",
    "model = k.models.load_model('full_convolution')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_validation, y_validation = np.array([*dataset_validation.as_numpy_iterator()]).T\n",
    "X_validation = np.array([item['char'] for item in X_validation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_validation2 = tf.data.Dataset.from_tensor_slices(((X_validation, X_validation),)).batch(bs)\n",
    "y_validation = y_validation.astype('int32')\n",
    "\n",
    "y_hat = model.predict(X_validation2).ravel()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_validation, y_hat)\n",
    "auc_ = auc(fpr, tpr)\n",
    "best_threshold = thresholds[np.argmax(-fpr + tpr)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_name = \"Fully Convolutional Word\"\n",
    "model_full_name = \"Fully Convolutional model with Word Level Embedding\"\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr, label=f'{model_name} (area = {auc_:.3f})')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title(f'ROC curve for {model_full_name}')\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(f'../plots/{model_name.replace(\" \", \"_\").lower()}_roc.pdf')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_hat_01 = np.zeros_like(y_hat)\n",
    "y_hat_01[y_hat >= best_threshold] = 1\n",
    "\n",
    "np.unique(y_hat_01)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "precision_recall_fscore_support(y_validation, y_hat_01, beta=1, average='binary'), \\\n",
    "    tpr[np.argmax(-fpr + tpr)], fpr[np.argmax(-fpr + tpr)], \\\n",
    "    accuracy_score(y_validation, y_hat_01)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot((-fpr + tpr) / 2, label='Sum')\n",
    "plt.plot(tpr, label='TPR')\n",
    "plt.plot(1-fpr, label='FPR')\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.save(\"fpr_tpr/fccl-fpr\", fpr)\n",
    "np.save(\"fpr_tpr/fccl-tpr\", tpr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}